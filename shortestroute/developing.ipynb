{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mingpt.utils import set_seed\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from mingpt.model import GPT\n",
    "from mingpt.trainer import Trainer\n",
    "from mingpt.utils import set_seed, setup_logging, CfgNode as CN\n",
    "import time\n",
    "\n",
    "import routegym.env\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity = 0.53\n",
      "[[0 1 1 1 1 0 0 0 1 0 1 1]\n",
      " [0 0 1 1 0 0 0 0 1 1 0 1]\n",
      " [1 0 0 1 1 1 0 0 0 1 0 1]\n",
      " [1 1 1 0 0 0 1 1 1 0 1 0]\n",
      " [1 1 0 0 0 1 0 1 0 0 0 1]\n",
      " [1 1 1 1 1 0 0 0 1 1 1 0]\n",
      " [0 1 1 1 1 1 0 1 0 0 1 0]\n",
      " [0 0 1 0 1 1 0 0 1 0 1 0]\n",
      " [0 1 1 0 0 0 0 1 0 1 0 1]\n",
      " [0 1 0 0 0 0 1 1 0 0 1 1]\n",
      " [0 0 0 0 1 0 0 0 0 1 0 1]\n",
      " [0 1 1 1 0 0 0 1 0 0 0 0]]\n",
      "[[-1  1  1  1  1  1 -1 -1  1 -1  1  1]\n",
      " [ 1 -1  1  1  1  1  1 -1  1  1 -1  1]\n",
      " [ 1  1 -1  1  1  1  1  1  1  1 -1  1]\n",
      " [ 1  1  1 -1 -1  1  1  1  1 -1  1  1]\n",
      " [ 1  1  1 -1 -1  1  1  1 -1 -1  1  1]\n",
      " [ 1  1  1  1  1 -1  1  1  1  1  1 -1]\n",
      " [-1  1  1  1  1  1 -1  1 -1  1  1 -1]\n",
      " [-1 -1  1  1  1  1  1 -1  1  1  1  1]\n",
      " [ 1  1  1  1 -1  1 -1  1 -1  1 -1  1]\n",
      " [-1  1  1 -1 -1  1  1  1  1 -1  1  1]\n",
      " [ 1 -1 -1  1  1  1  1  1 -1  1 -1  1]\n",
      " [ 1  1  1  1  1 -1 -1  1  1  1  1 -1]]\n"
     ]
    }
   ],
   "source": [
    "node_number = 12\n",
    "\n",
    "env = None\n",
    "while env is None:\n",
    "    try:\n",
    "        A = sp.sparse.random(node_number, node_number, density=0.5, format='csr')\n",
    "        A.data[:] = 1\n",
    "        A = A.todense()\n",
    "        A = np.ma.array(A, mask=np.eye(node_number)).filled(fill_value=0).astype(int)\n",
    "        print(\"sparsity = %.2f\" % (1 - np.sum(A)/A.size))\n",
    "        G = nx.from_numpy_array(A)\n",
    "        env = routegym.env.ShortestRouteEnv(G, 0, 5, random_weights=(1,10))\n",
    "    except:\n",
    "        pass\n",
    "# env.render()\n",
    "print(A)\n",
    "print(env.graph.adj_mat)\n",
    "# print(env.get_dijkstra())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(30):\n",
    "    env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: {1, 4, 4, 4, 6, 6, 6, 6, 7, 10, 6, 4, 10, 10, 7, 10, 6, 6, 7, 6, 4, 11, 11, 11, 0, 5, }\n",
      "\n",
      "Final reward: -25.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rew = 0\n",
    "position = 0\n",
    "env.reset()\n",
    "done = False\n",
    "print(\"Position: {\", end='')\n",
    "while not done:\n",
    "    action = np.random.choice(np.arange(0, env.graph.adj_mat.shape[0]))\n",
    "    position, reward, done, _ = env.step(action)\n",
    "    # env.render()\n",
    "    print(\"%d, \" % position, end='')\n",
    "    rew += reward\n",
    "print(\"}\\n\")\n",
    "print(\"Final reward: %.2f\" % rew)\n",
    "env.reset()\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "num_steps = 10_000\n",
    "\n",
    "def create_dataset():\n",
    "    obss = []\n",
    "    actions = []\n",
    "    returns = [0]\n",
    "    done_idxs = []\n",
    "    stepwise_returns = []\n",
    "\n",
    "    # simulate to create trajectories\n",
    "    transitions_per_buffer = np.zeros(50, dtype=int)\n",
    "    num_trajectories = 0\n",
    "    while len(obss) < num_steps:\n",
    "        done = False\n",
    "        for _ in range(10):\n",
    "            ac = np.random.choice(np.arange(0, env.graph.adj_mat.shape[0]))\n",
    "            state, reward, done, _ = env.step(ac)\n",
    "            obss += [state]\n",
    "            actions += [ac]\n",
    "            stepwise_returns += [reward]\n",
    "            returns[-1] += reward\n",
    "        # done = False\n",
    "        env.reset()\n",
    "        done_idxs += [len(obss)]\n",
    "        returns += [0]\n",
    "\n",
    "    actions = np.array(actions)\n",
    "    returns = np.array(returns)\n",
    "    stepwise_returns = np.array(stepwise_returns)\n",
    "    done_idxs = np.array(done_idxs)\n",
    "\n",
    "    # create reward-to-go dataset\n",
    "    start_index = 0\n",
    "    rtg = np.zeros_like(stepwise_returns)\n",
    "    for i in done_idxs:\n",
    "        i = int(i)\n",
    "        curr_traj_returns = stepwise_returns[start_index:i]\n",
    "        for j in range(i-1, start_index-1, -1): # start from i-1\n",
    "            rtg_j = curr_traj_returns[j-start_index:i-start_index]\n",
    "            rtg[j] = sum(rtg_j)\n",
    "        start_index = i\n",
    "    print('max rtg is %d' % max(rtg))\n",
    "\n",
    "    # create timestep dataset\n",
    "    start_index = 0\n",
    "    timesteps = np.zeros(len(actions)+1, dtype=int)\n",
    "    for i in done_idxs:\n",
    "        i = int(i)\n",
    "        timesteps[start_index:i+1] = np.arange(i+1 - start_index)\n",
    "        start_index = i+1\n",
    "    print('max timesteps is %d' % max(timesteps))\n",
    "\n",
    "    return obss, actions, returns, done_idxs, rtg, timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max rtg is 0\n",
      "max timesteps is 10\n",
      "-6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obss, actions, returns, done_idxs, rtgs, timesteps = create_dataset()\n",
    "print(returns[:-1].max())\n",
    "timesteps[25:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateActionReturnDataset(Dataset):\n",
    "\n",
    "    @staticmethod\n",
    "    def get_default_config():\n",
    "        C = CN()\n",
    "        C.block_size = 10 * 3\n",
    "        return C\n",
    "\n",
    "    def __init__(self, data, block_size, actions, done_idxs, rtgs, timesteps):\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = max(actions) + 1\n",
    "        self.data = data\n",
    "        self.actions = actions\n",
    "        self.done_idxs = done_idxs\n",
    "        self.rtgs = rtgs\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        block_size = self.block_size // 3\n",
    "        done_idx = idx + block_size\n",
    "        for i in self.done_idxs:\n",
    "            if i > idx: # first done_idx is greater than idx\n",
    "                done_idx = min(int(i), done_idx)\n",
    "                break\n",
    "        idx = done_idx - block_size\n",
    "        states = torch.tensor(np.array(self.data[idx:done_idx]), dtype=torch.float32).reshape(block_size, -1) # (block_size, state_dim)\n",
    "        actions = torch.tensor(self.actions[idx:done_idx], dtype=torch.long).unsqueeze(1) # (block_size, 1)\n",
    "        rtgs = torch.tensor(self.rtgs[idx:done_idx], dtype=torch.float32).unsqueeze(1) # (block_size, 1)\n",
    "        timesteps = torch.tensor(self.timesteps[idx:idx+1], dtype=torch.int64).unsqueeze(1) # (block_size, 1)\n",
    "\n",
    "        return states, actions, rtgs, timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = CN()\n",
    "\n",
    "# system\n",
    "C.system = CN()\n",
    "C.system.seed = 3407\n",
    "C.system.work_dir = './out/decgpt'\n",
    "\n",
    "# data\n",
    "C.data = StateActionReturnDataset.get_default_config()\n",
    "\n",
    "# model \n",
    "C.model = GPT.get_default_config()\n",
    "C.model.model_type = 'gpt-mini'\n",
    "\n",
    "# trainer\n",
    "C.trainer = Trainer.get_default_config()\n",
    "C.trainer.learning_rate = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = StateActionReturnDataset(obss, 10 * 3, actions, done_idxs, rtgs, timesteps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "C.model.vocab_size = train_dataset.vocab_size\n",
    "C.model.block_size = train_dataset.block_size\n",
    "C.model.max_timestep = max(timesteps)\n",
    "C.model.max_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 2.68M\n"
     ]
    }
   ],
   "source": [
    "model = GPT(C.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, r, t = train_dataset[np.random.randint(0, 10_000, 1)]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (642224348.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    loader = DataLoader(train_dataset, shuffle=True, pin_memory=True, batch_size=4))\u001b[0m\n\u001b[0m                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(train_dataset, shuffle=True, pin_memory=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 192])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (10) at non-singleton dimension 1.  Target sizes: [10, 1, 192].  Tensor sizes: [10, 192]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/dec-transformer-route/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/dec-transformer-route/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/research/transformers/shortestroute/mingpt/model.py:289\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, states, actions, targets, rtgs, timesteps)\u001b[0m\n\u001b[1;32m    287\u001b[0m tok_emb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((states\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], states\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mn_embd), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39ms_embedding\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mprint\u001b[39m(r_embedding\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 289\u001b[0m \u001b[43mtok_emb\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m r_embedding\n\u001b[1;32m    290\u001b[0m tok_emb[:, \u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m3\u001b[39m, :] \u001b[38;5;241m=\u001b[39m s_embedding\n\u001b[1;32m    291\u001b[0m tok_emb[:, \u001b[38;5;241m2\u001b[39m::\u001b[38;5;241m3\u001b[39m, :] \u001b[38;5;241m=\u001b[39m a_embedding[:, \u001b[38;5;241m-\u001b[39mstates\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):, :]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (10) at non-singleton dimension 1.  Target sizes: [10, 1, 192].  Tensor sizes: [10, 192]"
     ]
    }
   ],
   "source": [
    "model(x, y, y, r, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dec-transformer-route",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
